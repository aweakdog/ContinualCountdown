version: '3'
services:
  evaluator:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
      - ./metrics:/app/metrics  # For metrics input
      - ./plots:/app/plots    # For evaluation plots
      - ./logs:/app/logs    # For training logs
    container_name: countdown-evaluator
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0  # Only need one GPU for evaluation
      - METRICS_DIR=/app/metrics
      - PLOTS_DIR=/app/plots
      - LOGS_DIR=/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: '8gb'  # Reduced shared memory since we only need one GPU
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /app/metrics /app/plots /app/logs &&
        # First evaluate 0.5B model
        conda run -n zero bash scripts/eval_continual_countdown.sh --model-size 0.5b &&
        # Then evaluate 1.5B model
        conda run -n zero bash scripts/eval_continual_countdown.sh --model-size 1.5b
      '

  data-generator:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
    container_name: countdown-data-generator
    working_dir: /app
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /data/continual &&
        chmod -R 777 /data/continual &&
        python experiments/continual/data_gen_efficient.py
      '

  continual-trainer-0.5b:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
      - ./wandb:/app/wandb  # For WandB logs
      - ./logs:/app/logs    # For training logs
      - ~/model/qwen0.5b:/app/models/qwen:ro  # Mount Qwen model as read-only
      - ./models/countdown_continual:/app/models/countdown_continual  # Mount trained model directory
      - ./metrics:/app/metrics  # For metrics output
    container_name: countdown-continual-trainer-0.5b
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - BASE_MODEL=/app/models/qwen  # Path to mounted Qwen model
      - N_GPUS=8  # Using all 8 3090 GPUs
      - ROLLOUT_TP_SIZE=2  # Using tensor parallel size 2 for Qwen-0.5B's 14 attention heads
      - DATA_DIR=/data/continual  # Match the mounted data path
      - WANDB_MODE=offline  # Run WandB in offline mode to avoid API key requirement
      - VLLM_ATTENTION_BACKEND=XFORMERS  # As specified in OLD_README.md
      - CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 8
              capabilities: [gpu]
    shm_size: '64gb'  # Increased shared memory for multi-GPU training
    ulimits:
      memlock: -1  # Remove memory lock limits
      stack: 67108864  # Increase stack size
    ipc: host  # Use host IPC namespace for better inter-process communication
    working_dir: /app

  continual-trainer-1.5b:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app
      - ./data:/data/continual
      - ./checkpoints:/app/checkpoints
      - ./metrics:/app/metrics
      - ./logs:/app/logs
      - ./wandb:/app/wandb
    container_name: countdown-trainer-1.5b
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - WANDB_PROJECT=ContinualCountdown1.5B
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: '64gb'
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /app/checkpoints /app/metrics /app/logs /app/wandb &&
        conda run -n zero bash scripts/train_continual_countdown_1.5b.sh
      '

  countdown-viewer:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
    container_name: countdown-viewer
    working_dir: /app
    stdin_open: true  # Keep STDIN open for interactive use
    tty: true        # Allocate a pseudo-TTY
    command: >
      bash -c '
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        python tmp/show_data.py
      '

  curriculum-trainer-1.5b:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app
      - ./data:/data/continual
      - ./checkpoints:/app/checkpoints
      - ./metrics:/app/metrics
      - ./logs:/app/logs
      - ./wandb:/app/wandb
      - ~/model/qwen1.5b:/app/models/qwen1.5b:ro
      - ./models/countdown_continual_1.5b:/app/models/countdown_continual_1.5b
    depends_on:
      - data-generator
    container_name: countdown-curriculum-1.5b
    tty: true
    stdin_open: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 8
              capabilities: [gpu]
    shm_size: '64gb'
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONUNBUFFERED=1
      - BASE_MODEL=/app/models/qwen1.5b
      - N_GPUS=8
      - ROLLOUT_TP_SIZE=2
      - DATA_DIR=/data/continual
      - WANDB_MODE=offline
      - VLLM_ATTENTION_BACKEND=XFORMERS
      - CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
      - NCCL_DEBUG=INFO
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /app/checkpoints /app/metrics /app/logs /app/wandb &&
        chmod +x /app/scripts/train_continual_countdown_1.5b_curriculum.sh &&
        exec conda run -n zero bash /app/scripts/train_continual_countdown_1.5b_curriculum.sh
      '
