version: '3'
services:
  evaluator:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
      - ./metrics:/app/metrics  # For metrics input
      - ./plots:/app/plots    # For evaluation plots
      - ./logs:/app/logs    # For training logs
    container_name: countdown-evaluator
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0  # Only need one GPU for evaluation
      - METRICS_DIR=/app/metrics
      - PLOTS_DIR=/app/plots
      - LOGS_DIR=/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: '8gb'  # Reduced shared memory since we only need one GPU
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /app/metrics /app/plots /app/logs &&
        # First evaluate 0.5B model
        conda run -n zero bash scripts/eval_continual_countdown.sh --model-size 0.5b &&
        # Then evaluate 1.5B model
        conda run -n zero bash scripts/eval_continual_countdown.sh --model-size 1.5b &&
        # Finally evaluate 3B model
        conda run -n zero bash scripts/eval_continual_countdown.sh --model-size 3b
      '

  data-generator:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - .:/app  # Mount entire project
      - ./data:/data/continual  # Mount data directory
    container_name: countdown-data-generator
    working_dir: /app
    command: >
      bash -c '
        git config --global --add safe.directory /app &&
        . /opt/conda/etc/profile.d/conda.sh &&
        conda activate zero &&
        mkdir -p /data/continual &&
        chmod -R 777 /data/continual &&
        python experiments/continual/data_gen_efficient.py
      '

  curriculum-trainer-1.5b:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      #- .:/app  # Mount entire project
      - ./data:/app/data  # Mount data directory
      - ./wandb:/app/wandb  # For WandB logs
      - ./logs:/app/logs    # For training logs
      - ~/model/qwen1.5b:/app/models/qwen1.5b:ro  # Mount Qwen model as read-only
      - ./metrics:/app/metrics  # For metrics output
      - ./checkpoints:/app/checkpoints  # Mount checkpoints directory
    container_name: countdown-curriculum-trainer-1.5b
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 8
              capabilities: [gpu]
    shm_size: '64gb'
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    command: >
      bash -c '
        bash scripts/train_continual_countdown_1.5b_curriculum.sh
      '

  curriculum-trainer-3b:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      #- .:/app  # Mount entire project
      - ./data:/app/data  # Mount data directory
      - ./wandb:/app/wandb  # For WandB logs
      - ./logs:/app/logs    # For training logs
      - ~/model/qwen3b:/app/models/qwen3b:ro  # Mount Qwen model as read-only
      - ./metrics:/app/metrics  # For metrics output
      - ./checkpoints:/app/checkpoints  # Mount checkpoints directory
    container_name: countdown-curriculum-trainer-3b
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 4
              capabilities: [gpu]
    shm_size: '128gb'  # Increased for larger model
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    working_dir: /app
    command: >
      bash -c '
        bash scripts/train_continual_countdown_3b_curriculum.sh
      '
